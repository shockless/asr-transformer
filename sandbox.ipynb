{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660f920-4dde-43c8-b7ba-517ef76ab722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:16.278349Z",
     "iopub.status.busy": "2023-05-18T11:25:16.278176Z",
     "iopub.status.idle": "2023-05-18T11:25:17.267612Z",
     "shell.execute_reply": "2023-05-18T11:25:17.267134Z",
     "shell.execute_reply.started": "2023-05-18T11:25:16.278331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from modules.Transformer.model import Transformer\n",
    "from modules.Transformer.train import train_epoch, eval_epoch\n",
    "from modules.dataset import AudioDataset\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553996c-2adf-44b8-a894-a1f6a2ceb5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:17.268329Z",
     "iopub.status.busy": "2023-05-18T11:25:17.268151Z",
     "iopub.status.idle": "2023-05-18T11:25:17.270670Z",
     "shell.execute_reply": "2023-05-18T11:25:17.270239Z",
     "shell.execute_reply.started": "2023-05-18T11:25:17.268316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_tokenizer = './tokenizer.json'\n",
    "path_to_data = './audio_dataset/'\n",
    "\n",
    "data = pd.read_csv(os.path.join(path_to_data,'df.csv'), usecols=['text','status','path','rate','duration','frames'])\n",
    "data = data[data.status=='APPROVED'].reset_index(drop=True)\n",
    "del data['status']\n",
    "data.text = data.text.apply(lambda x: \"\".join([char for char in x if char.isalpha() or char==' ']).lower())\n",
    "data.duration.max()\n",
    "\n",
    "train_data = data.iloc[:10000]\n",
    "valid_data = data.iloc[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e324020-a3e7-46b8-9228-7cdf8b766904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:18.259359Z",
     "iopub.status.busy": "2023-05-18T11:25:18.258861Z",
     "iopub.status.idle": "2023-05-18T11:25:19.342932Z",
     "shell.execute_reply": "2023-05-18T11:25:19.342378Z",
     "shell.execute_reply.started": "2023-05-18T11:25:18.259345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.displot(data.text.str.len())\n",
    "# plt.show()dd\n",
    "# sns.displot(data.duration)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8268447-41ef-4582-9100-4e0afb378fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.343930Z",
     "iopub.status.busy": "2023-05-18T11:25:19.343621Z",
     "iopub.status.idle": "2023-05-18T11:25:19.363838Z",
     "shell.execute_reply": "2023-05-18T11:25:19.363307Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.343911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.percentile(data.text.str.len(), 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94db526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_xavier(m):\n",
    "    '''\n",
    "    Xavier uniform\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f94ee00-973a-4a23-ae2a-a0cef7807450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.461107Z",
     "iopub.status.busy": "2023-05-18T11:25:19.460893Z",
     "iopub.status.idle": "2023-05-18T11:25:19.583274Z",
     "shell.execute_reply": "2023-05-18T11:25:19.582767Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.461089Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=path_to_tokenizer, \n",
    "                                    padding_side ='right',\n",
    "                                    bos_token = '[SOS]',\n",
    "                                    eos_token = '[EOS]',\n",
    "                                    pad_token = '[PAD]',\n",
    "                                    unk_token = '[UNK]',\n",
    "                                    mask_token = '[MASK]')\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(train_data, path_to_data, tokenizer, \n",
    "                             n_fft=512,\n",
    "                             n_mels=128, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "valid_dataset = AudioDataset(valid_data, path_to_data, tokenizer, \n",
    "                             n_fft=512, \n",
    "                             n_mels=128, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "model = Transformer(vocab_size=len(tokenizer),\n",
    "                    n_mels=128,\n",
    "                    enc_seq_len=25, \n",
    "                    dec_seq_len=100,\n",
    "                    hidden_dim=16, \n",
    "                    enc_num_layers=2, \n",
    "                    dec_num_layers=2, \n",
    "                    num_heads=3, \n",
    "                    ff_dim=128, \n",
    "                    device=device,\n",
    "                    dropout=0.0, \n",
    "                    sr=16000, \n",
    "                    n_fft=512,\n",
    "                    padding_idx=tokenizer.pad_token_id)\n",
    "\n",
    "\n",
    "        #.bias.data.fill_(0.01)\n",
    "model.apply(weights_init_xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef55a1-3645-448c-beee-565d8cc5ee39",
   "metadata": {},
   "source": [
    "n_fft=1024, win_lenght=1024, hop_lenght=256, n_mels=64, center=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94544c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import word_error_rate\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, \n",
    "                     dataset, \n",
    "                     loss_function,\n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=10, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-3,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=4,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "            run = wandb.init(\n",
    "                name=f\"fold_{fold}\",\n",
    "                project=f\"asr_fold_{fold}\",\n",
    "                config={ \n",
    "                         \"random_state\": random_state, \n",
    "                         \"shuffle\": shuffle,\n",
    "                         \"epochs\": epochs, \n",
    "                         \"learning_rate\": lr,\n",
    "                         \"batch_size\": batch_size,\n",
    "                         \"iters_to_accumulate\": iters_to_accumulate\n",
    "                        })\n",
    "\n",
    "            optimizer = AdamW(model.parameters(), lr=lr\n",
    "#                 [{\"params\": model.encoder.parameters(), \"lr\": 1e-4},\n",
    "#                 {\"params\": model.decoder.parameters(), \"lr\": 1e-3},]\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "            for epoch_i in range(epochs):\n",
    "                train_metrics, t_preds = train_epoch(model, train_loader, dataset.tokenizer, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics, preds = eval_epoch(model, eval_loader, dataset.tokenizer, loss_function, device)\n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                print(t_preds)\n",
    "                print(preds)\n",
    "                run.log(train_metrics)\n",
    "                run.log(eval_metrics)\n",
    "                            \n",
    "            run.finish()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d83303",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = tokenizer.encode(\"я люблю дашу\")\n",
    "tokenizer.decode(string, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67efaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]['encoded_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]['true_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7e833",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_validation(model = model,\n",
    "                 dataset=train_dataset, \n",
    "                 loss_function=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction=\"mean\"), \n",
    "                 device=torch.device(\"cuda\"),\n",
    "                 random_state=69,\n",
    "                 shuffle=True,\n",
    "                 batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
