{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a660f920-4dde-43c8-b7ba-517ef76ab722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:16.278349Z",
     "iopub.status.busy": "2023-05-18T11:25:16.278176Z",
     "iopub.status.idle": "2023-05-18T11:25:17.267612Z",
     "shell.execute_reply": "2023-05-18T11:25:17.267134Z",
     "shell.execute_reply.started": "2023-05-18T11:25:16.278331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from modules.Transformer.model import Transformer\n",
    "from modules.Transformer.train import train_epoch, eval_epoch\n",
    "from modules.dataset import AudioDataset\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553996c-2adf-44b8-a894-a1f6a2ceb5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:17.268329Z",
     "iopub.status.busy": "2023-05-18T11:25:17.268151Z",
     "iopub.status.idle": "2023-05-18T11:25:17.270670Z",
     "shell.execute_reply": "2023-05-18T11:25:17.270239Z",
     "shell.execute_reply.started": "2023-05-18T11:25:17.268316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_tokenizer = './tokenizer.json'\n",
    "path_to_data = './audio_dataset/'\n",
    "\n",
    "data = pd.read_csv(os.path.join(path_to_data,'df.csv'), usecols=['text','status','path','rate','duration','frames'])\n",
    "data = data[data.status=='APPROVED'].reset_index(drop=True)\n",
    "del data['status']\n",
    "data.text = data.text.apply(lambda x: \"\".join([char for char in x if char.isalpha() or char==' ']).lower())\n",
    "data.duration.max()\n",
    "\n",
    "train_data = data.iloc[:1000]\n",
    "valid_data = data.iloc[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e324020-a3e7-46b8-9228-7cdf8b766904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:18.259359Z",
     "iopub.status.busy": "2023-05-18T11:25:18.258861Z",
     "iopub.status.idle": "2023-05-18T11:25:19.342932Z",
     "shell.execute_reply": "2023-05-18T11:25:19.342378Z",
     "shell.execute_reply.started": "2023-05-18T11:25:18.259345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.displot(data.text.str.len())\n",
    "# plt.show()dd\n",
    "# sns.displot(data.duration)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8268447-41ef-4582-9100-4e0afb378fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.343930Z",
     "iopub.status.busy": "2023-05-18T11:25:19.343621Z",
     "iopub.status.idle": "2023-05-18T11:25:19.363838Z",
     "shell.execute_reply": "2023-05-18T11:25:19.363307Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.343911Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data.text.str.len(), 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94db526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_xavier(m):\n",
    "    '''\n",
    "    Xavier uniform\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f94ee00-973a-4a23-ae2a-a0cef7807450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.461107Z",
     "iopub.status.busy": "2023-05-18T11:25:19.460893Z",
     "iopub.status.idle": "2023-05-18T11:25:19.583274Z",
     "shell.execute_reply": "2023-05-18T11:25:19.582767Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.461089Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (vgg): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (lin_in): Linear(in_features=40, out_features=40, bias=True)\n",
       "    (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "    (pe): TrainablePositionalEncoding()\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): MHA(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (heads): ModuleList(\n",
       "            (0-2): 3 x MHAHead(\n",
       "              (v): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (q): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (k): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (out): Linear(in_features=120, out_features=40, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (squeeze): Linear(in_features=40, out_features=128, bias=True)\n",
       "          (ReLU): ReLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (unsqueeze): Linear(in_features=128, out_features=40, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (emb): Embedding(250, 40, padding_idx=4)\n",
       "    (pe): TrainablePositionalEncoding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (mask_attention): MHA(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (heads): ModuleList(\n",
       "            (0-2): 3 x MHAHead(\n",
       "              (v): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (q): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (k): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (out): Linear(in_features=120, out_features=40, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MHA(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (heads): ModuleList(\n",
       "            (0-2): 3 x MHAHead(\n",
       "              (v): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (q): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (k): Linear(in_features=40, out_features=40, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (out): Linear(in_features=120, out_features=40, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (squeeze): Linear(in_features=40, out_features=128, bias=True)\n",
       "          (ReLU): ReLU()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (unsqueeze): Linear(in_features=128, out_features=40, bias=True)\n",
       "        )\n",
       "        (norm3): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=40, out_features=250, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=path_to_tokenizer, \n",
    "                                    padding_side ='right',\n",
    "                                    bos_token = '[SOS]',\n",
    "                                    eos_token = '[EOS]',\n",
    "                                    pad_token = '[PAD]',\n",
    "                                    unk_token = '[UNK]',\n",
    "                                    mask_token = '[MASK]')\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(train_data, path_to_data, tokenizer, \n",
    "                             n_fft=512,\n",
    "                             n_mels=40, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "valid_dataset = AudioDataset(valid_data, path_to_data, tokenizer, \n",
    "                             n_fft=512, \n",
    "                             n_mels=128, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "model = Transformer(vocab_size=len(tokenizer),\n",
    "                    n_mels=40,\n",
    "                    enc_seq_len=25, \n",
    "                    dec_seq_len=100,\n",
    "                    hidden_dim=16, \n",
    "                    enc_num_layers=2, \n",
    "                    dec_num_layers=2, \n",
    "                    num_heads=3, \n",
    "                    ff_dim=128, \n",
    "                    device=device,\n",
    "                    dropout=0.0, \n",
    "                    sr=16000, \n",
    "                    n_fft=512,\n",
    "                    padding_idx=tokenizer.pad_token_id)\n",
    "\n",
    "\n",
    "        #.bias.data.fill_(0.01)\n",
    "model.apply(weights_init_xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef55a1-3645-448c-beee-565d8cc5ee39",
   "metadata": {},
   "source": [
    "n_fft=1024, win_lenght=1024, hop_lenght=256, n_mels=64, center=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d6466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94544c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import word_error_rate\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, \n",
    "                     dataset, \n",
    "                     loss_function,\n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=10, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-3,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=4,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "            run = wandb.init(\n",
    "                name=f\"fold_{fold}\",\n",
    "                project=f\"asr_fold_{fold}\",\n",
    "                config={ \n",
    "                         \"random_state\": random_state, \n",
    "                         \"shuffle\": shuffle,\n",
    "                         \"epochs\": epochs, \n",
    "                         \"learning_rate\": lr,\n",
    "                         \"batch_size\": batch_size,\n",
    "                         \"iters_to_accumulate\": iters_to_accumulate\n",
    "                        })\n",
    "\n",
    "            optimizer = AdamW(model.parameters(), lr=lr\n",
    "#                 [{\"params\": model.encoder.parameters(), \"lr\": 1e-4},\n",
    "#                 {\"params\": model.decoder.parameters(), \"lr\": 1e-3},]\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = len(train_loader)*2, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "            #scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, total_iters=0)\n",
    "            for epoch_i in range(epochs):\n",
    "                train_metrics, t_preds = train_epoch(model, train_loader, dataset.tokenizer, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics, preds = eval_epoch(model, eval_loader, dataset.tokenizer, loss_function, device)\n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                print(t_preds)\n",
    "                print(preds)\n",
    "                run.log(train_metrics)\n",
    "                run.log(eval_metrics)\n",
    "                            \n",
    "            run.finish()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d83303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я люблю дашу'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = tokenizer.encode(\"я люблю дашу\")\n",
    "tokenizer.decode(string, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92943ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67efaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'этот процесс так захватывает человека что он отвлекается от переживаний переключаясь на чтото иное',\n",
       " 'encoded_text': tensor([  1,  93, 184, 103, 209,  86,  69,  81, 104, 204, 107, 196,  85, 188,\n",
       "          82,  91, 188, 234, 220, 208, 205,  74, 101, 244,  78, 121, 245,  66,\n",
       "         207, 190,  69, 237,  78, 103, 227, 182,  70,  72, 188, 186, 102, 227,\n",
       "         182,  74,  75,  94, 238,  95,  81, 106, 202,  87, 184, 195,  72, 183,\n",
       "         112,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "           2,   2]),\n",
       " 'spectre': tensor([[[0.0000e+00, 2.6849e-03, 6.1225e-02,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.8886e-03, 2.6989e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.9776e-03, 2.2738e-01,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 8.8953e-05, 3.7881e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.6801e-05, 3.0835e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.8335e-05, 1.7517e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]]),\n",
       " 'audio': tensor([[0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'sr': 16000,\n",
       " 'spectrogram_len': 940,\n",
       " 'text_len': 58,\n",
       " 'true_text': tensor([ 93, 184, 103, 209,  86,  69,  81, 104, 204, 107, 196,  85, 188,  82,\n",
       "          91, 188, 234, 220, 208, 205,  74, 101, 244,  78, 121, 245,  66, 207,\n",
       "         190,  69, 237,  78, 103, 227, 182,  70,  72, 188, 186, 102, 227, 182,\n",
       "          74,  75,  94, 238,  95,  81, 106, 202,  87, 184, 195,  72, 183, 112,\n",
       "           2,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "           4,   4])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshockless\u001b[0m (\u001b[33mfedor-avilov\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\fedor\\PycharmProjects\\asr-transformer\\wandb\\run-20230606_010342-8mh5k2sz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fedor-avilov/asr_fold_0/runs/8mh5k2sz' target=\"_blank\">fold_0</a></strong> to <a href='https://wandb.ai/fedor-avilov/asr_fold_0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fedor-avilov/asr_fold_0' target=\"_blank\">https://wandb.ai/fedor-avilov/asr_fold_0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fedor-avilov/asr_fold_0/runs/8mh5k2sz' target=\"_blank\">https://wandb.ai/fedor-avilov/asr_fold_0/runs/8mh5k2sz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ecc7752367499ba2f5201545e98dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40618851b3c94d35b01256c280aea9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "{'Train Loss': 5.189449599811009, 'Train Word Accuracy': -0.41356360912323, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 4.783752838770549, 'Val Word Accuracy': 0.0, 'Val Accuracy': 0.0}\n",
      "сссссссссссссссссссссссссссссссссссссссссссссс\n",
      "сссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссс\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed58f5774d749c68fc9fe6ddef16cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefdc03e1ff4431d8d188905b8543d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "{'Train Loss': 4.712824259485517, 'Train Word Accuracy': 0.0, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 4.741640329360962, 'Val Word Accuracy': -0.009872078895568848, 'Val Accuracy': 0.0}\n",
      "сссссссссссссссссссссссссссссссссссссссссссссссисссссс\n",
      "мсисссисисссисисисисисе се се се свса а са\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc5f85323a24e1eaa98b7fc09f891ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5eb77effc2437797a214d5ae8add66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "{'Train Loss': 4.465691404683249, 'Train Word Accuracy': -0.03625190258026123, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 5.129363854726155, 'Val Word Accuracy': -2.0308568477630615, 'Val Accuracy': 0.0}\n",
      "в тотоадкисссасущнщсиасусений суассенй яссдужинесснсии сенв ть й сиздсеза ежа жасенй й и\n",
      "в ский сь сущизизизим в саням в санях в сал и посанях санях ский саны й санях й й ский ский санях й й й й й й й саны ы ы\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888dd98460d34eefb9c37c6b28af9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_validation(model = model,\n",
    "                 dataset=train_dataset, \n",
    "                 loss_function=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id), \n",
    "                 device=torch.device(\"cuda\"),\n",
    "                 random_state=69,\n",
    "                 shuffle=True,\n",
    "                 batch_size=16,\n",
    "                 lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a33e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6ad75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
