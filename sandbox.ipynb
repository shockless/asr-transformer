{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a660f920-4dde-43c8-b7ba-517ef76ab722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:16.278349Z",
     "iopub.status.busy": "2023-05-18T11:25:16.278176Z",
     "iopub.status.idle": "2023-05-18T11:25:17.267612Z",
     "shell.execute_reply": "2023-05-18T11:25:17.267134Z",
     "shell.execute_reply.started": "2023-05-18T11:25:16.278331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from modules.model import Transformer, train_epoch, eval_epoch\n",
    "from modules.dataset import AudioDataset\n",
    "from modules.tokenizer import tokenize\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553996c-2adf-44b8-a894-a1f6a2ceb5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:17.268329Z",
     "iopub.status.busy": "2023-05-18T11:25:17.268151Z",
     "iopub.status.idle": "2023-05-18T11:25:17.270670Z",
     "shell.execute_reply": "2023-05-18T11:25:17.270239Z",
     "shell.execute_reply.started": "2023-05-18T11:25:17.268316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_tokenizer = './tokenizer.json'\n",
    "path_to_data = './audio_dataset/'\n",
    "\n",
    "data = pd.read_csv(os.path.join(path_to_data,'df.csv'), usecols=['text','status','path','rate','duration','frames'])\n",
    "data = data[data.status=='APPROVED'].reset_index(drop=True)\n",
    "del data['status']\n",
    "data.text = data.text.apply(lambda x: \"\".join([char for char in x if char.isalpha() or char==' ']).lower())\n",
    "data.duration.max()\n",
    "\n",
    "train_data = data.iloc[:10000]\n",
    "valid_data = data.iloc[10000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e324020-a3e7-46b8-9228-7cdf8b766904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:18.259359Z",
     "iopub.status.busy": "2023-05-18T11:25:18.258861Z",
     "iopub.status.idle": "2023-05-18T11:25:19.342932Z",
     "shell.execute_reply": "2023-05-18T11:25:19.342378Z",
     "shell.execute_reply.started": "2023-05-18T11:25:18.259345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.displot(data.text.str.len())\n",
    "# plt.show()dd\n",
    "# sns.displot(data.duration)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8268447-41ef-4582-9100-4e0afb378fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.343930Z",
     "iopub.status.busy": "2023-05-18T11:25:19.343621Z",
     "iopub.status.idle": "2023-05-18T11:25:19.363838Z",
     "shell.execute_reply": "2023-05-18T11:25:19.363307Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.343911Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data.text.str.len(), 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f94ee00-973a-4a23-ae2a-a0cef7807450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.461107Z",
     "iopub.status.busy": "2023-05-18T11:25:19.460893Z",
     "iopub.status.idle": "2023-05-18T11:25:19.583274Z",
     "shell.execute_reply": "2023-05-18T11:25:19.582767Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.461089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=path_to_tokenizer, \n",
    "                                    padding_side ='right',\n",
    "                                    bos_token = '[SOS]',\n",
    "                                    eos_token = '[EOS]',\n",
    "                                    pad_token = '[PAD]',\n",
    "                                    unk_token = '[UNK]',\n",
    "                                    mask_token = '[MASK]')\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(train_data, path_to_data, tokenizer, n_fft=1024, n_mels=64, center=True, max_tokenized_length=100, max_audio_len=25, sr=16000)\n",
    "valid_dataset = AudioDataset(valid_data, path_to_data, tokenizer, n_fft=1024, n_mels=64, center=True, max_tokenized_length=100, max_audio_len=25, sr=16000)\n",
    "model = Transformer(vocab_size=len(tokenizer),\n",
    "                    n_mels=64,\n",
    "                    enc_seq_len=25, \n",
    "                    dec_seq_len=100,\n",
    "                    hidden_dim=32, \n",
    "                    enc_num_layers=2, \n",
    "                    dec_num_layers=2, \n",
    "                    num_heads=3, \n",
    "                    ff_dim=128, \n",
    "                    r_dim=100, \n",
    "                    device=device,\n",
    "                    dropout=0.1, \n",
    "                    sr=16000, \n",
    "                    n_fft=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef55a1-3645-448c-beee-565d8cc5ee39",
   "metadata": {},
   "source": [
    "n_fft=1024, win_lenght=1024, hop_lenght=256, n_mels=64, center=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d6466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a528dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import word_error_rate\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abfff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, tokenizer, loss_function, optimizer, scheduler, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        batch['encoded_text'] = batch['encoded_text'].to(device)\n",
    "        batch['spectre'] = batch['spectre'].to(device)\n",
    "        batch['ohe_text'] = batch['ohe_text'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)\n",
    "        \n",
    "        pred = logits.argmax(dim=-1).to('cpu')\n",
    "        pred = [tokenizer.decode(i) for i in pred]\n",
    "        preds.append(pred)    \n",
    "        targets.append(batch['text'])\n",
    "        loss = loss_function(logits.transpose(1,2), batch['encoded_text'].squeeze())\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    acc_t = 0\n",
    "    wer = 0\n",
    "    for batch in range(dl_size):\n",
    "        acc = 0\n",
    "        for sample in range(len(preds[batch])):\n",
    "            acc += int(preds[batch][sample]==targets[batch][sample])\n",
    "                       \n",
    "        acc /= sample+1\n",
    "        wer += word_error_rate(preds[batch], targets[batch])\n",
    "        acc_t+=acc\n",
    "    acc_t = acc_t / dl_size\n",
    "    wer = wer / dl_size\n",
    "    metrics = {\n",
    "        \"Train Loss\": total_train_loss / dl_size,\n",
    "        \"Train WAcc\": 1 - wer.item(),\n",
    "        \"Train Accuracy\": acc,\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b1f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, data_loader,tokenizer, loss_function, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    dl_size = len(data_loader)\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        batch['encoded_text'] = batch['encoded_text'].to(device)\n",
    "        batch['spectre'] = batch['spectre'].to(device)\n",
    "        batch['ohe_text'] = batch['ohe_text'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred, logits = model.predict(batch,tokenizer.bos_token_id, tokenizer.eos_token_id,device)\n",
    "            pred = [tokenizer.decode(i) for i in pred]\n",
    "            preds.append(pred) \n",
    "            targets.append(batch['text'])\n",
    "\n",
    "        loss = loss_function(logits.transpose(1, 2), batch['encoded_text'].squeeze())\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    acc_t = 0\n",
    "    wer = 0\n",
    "    for batch in range(dl_size):\n",
    "        acc = 0\n",
    "        for sample in range(len(preds[batch])):\n",
    "            acc += int(preds[batch][sample]==targets[batch][sample])\n",
    "                       \n",
    "        acc /= sample+1\n",
    "        wer += word_error_rate(preds[batch], targets[batch])\n",
    "        acc_t+=acc\n",
    "    acc_t = acc_t/dl_size\n",
    "    wer = wer / (dl_size)\n",
    "    metrics = {\n",
    "        \"Val Loss\": total_train_loss / dl_size,\n",
    "        \"Val WAcc\": 1-wer.item(),\n",
    "        \"Val Accuracy\": acc,\n",
    "    }\n",
    "\n",
    "    return metrics, preds[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2bab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, \n",
    "                     dataset, \n",
    "                     loss_function,\n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=10, \n",
    "                     epochs: int=5, \n",
    "                     lr: float=1e-6,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=4,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "\n",
    "            optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            #lr = lr,\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "            for epoch_i in range(epochs):\n",
    "                train_metrics = train_epoch(model, train_loader, dataset.tokenizer, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics, preds = eval_epoch(model, eval_loader, dataset.tokenizer, loss_function, device)\n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics) \n",
    "                print(preds) \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea58bf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecae7d9001704733a83fa0c06adb5622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f417881462cf4b64a9e7820804297b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "{'Train Loss': 1.161193019236534, 'Train WAcc': -6.985538482666016, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 30.14263423796623, 'Val WAcc': -7.106573104858398, 'Val Accuracy': 0.0}\n",
      "[SOS] [SOS] [UNK] [MASK] [MASK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] ª [MASK] à [MASK] â ã ä ã ã ã ã ã ã ã ã ã ð ã ã ã ã ã ã ã ã ª ã ã ã ã ã ư ã ã ª ä ư ã à ж ã ä à ª â à ã ä ư ư [SOS] ã [SOS] ð ã à ã ã ä [UNK] ж à à ã ã ª ã [UNK] ª\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4b8bc578644e6d83e67c6ca214f1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa4dca0ae144d789afb4e9fa1d59391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model = model,\n",
    "                 dataset=train_dataset, \n",
    "                 loss_function=nn.CrossEntropyLoss(), \n",
    "                 device=torch.device(\"cuda\"),\n",
    "                 random_state=69,\n",
    "                 shuffle=True,\n",
    "                 batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368035c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
