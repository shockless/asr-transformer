{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a660f920-4dde-43c8-b7ba-517ef76ab722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:16.278349Z",
     "iopub.status.busy": "2023-05-18T11:25:16.278176Z",
     "iopub.status.idle": "2023-05-18T11:25:17.267612Z",
     "shell.execute_reply": "2023-05-18T11:25:17.267134Z",
     "shell.execute_reply.started": "2023-05-18T11:25:16.278331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from modules.Transformer.model import Transformer\n",
    "from modules.Transformer.train import train_epoch, eval_epoch\n",
    "from modules.dataset import AudioDataset\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553996c-2adf-44b8-a894-a1f6a2ceb5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:17.268329Z",
     "iopub.status.busy": "2023-05-18T11:25:17.268151Z",
     "iopub.status.idle": "2023-05-18T11:25:17.270670Z",
     "shell.execute_reply": "2023-05-18T11:25:17.270239Z",
     "shell.execute_reply.started": "2023-05-18T11:25:17.268316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_tokenizer = './tokenizer.json'\n",
    "path_to_data = './audio_dataset/'\n",
    "\n",
    "data = pd.read_csv(os.path.join(path_to_data,'df.csv'), usecols=['text','status','path','rate','duration','frames'])\n",
    "data = data[data.status=='APPROVED'].reset_index(drop=True)\n",
    "del data['status']\n",
    "data.text = data.text.apply(lambda x: \"\".join([char for char in x if char.isalpha() or char==' ']).lower())\n",
    "data.duration.max()\n",
    "\n",
    "train_data = data.iloc[:3000]\n",
    "valid_data = data.iloc[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e324020-a3e7-46b8-9228-7cdf8b766904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:18.259359Z",
     "iopub.status.busy": "2023-05-18T11:25:18.258861Z",
     "iopub.status.idle": "2023-05-18T11:25:19.342932Z",
     "shell.execute_reply": "2023-05-18T11:25:19.342378Z",
     "shell.execute_reply.started": "2023-05-18T11:25:18.259345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.displot(data.text.str.len())\n",
    "# plt.show()dd\n",
    "# sns.displot(data.duration)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8268447-41ef-4582-9100-4e0afb378fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.343930Z",
     "iopub.status.busy": "2023-05-18T11:25:19.343621Z",
     "iopub.status.idle": "2023-05-18T11:25:19.363838Z",
     "shell.execute_reply": "2023-05-18T11:25:19.363307Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.343911Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data.text.str.len(), 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94db526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_xavier(m):\n",
    "    '''\n",
    "    Xavier uniform\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f94ee00-973a-4a23-ae2a-a0cef7807450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T11:25:19.461107Z",
     "iopub.status.busy": "2023-05-18T11:25:19.460893Z",
     "iopub.status.idle": "2023-05-18T11:25:19.583274Z",
     "shell.execute_reply": "2023-05-18T11:25:19.582767Z",
     "shell.execute_reply.started": "2023-05-18T11:25:19.461089Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fedor\\AppData\\Local\\Temp\\ipykernel_3640\\1102778910.py:8: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (vgg): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (lin_in): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (norm_in): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (pe): TrainablePositionalEncoding()\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): MHA(\n",
       "          (query_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (key_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (value_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=2)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (output_linear): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (squeeze): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (ReLU): ReLU()\n",
       "          (unsqueeze): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (emb): Embedding(250, 128, padding_idx=4)\n",
       "    (pe): TrainablePositionalEncoding()\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (mask_attention): MHA(\n",
       "          (query_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (key_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (value_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=2)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (output_linear): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MHA(\n",
       "          (query_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (key_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (value_linear): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=2)\n",
       "          )\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (output_linear): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (squeeze): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (ReLU): ReLU()\n",
       "          (unsqueeze): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=128, out_features=250, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=path_to_tokenizer, \n",
    "                                    padding_side ='right',\n",
    "                                    bos_token = '[SOS]',\n",
    "                                    eos_token = '[EOS]',\n",
    "                                    pad_token = '[PAD]',\n",
    "                                    unk_token = '[UNK]',\n",
    "                                    mask_token = '[MASK]')\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(train_data, path_to_data, tokenizer, \n",
    "                             n_fft=512, \n",
    "                             n_mels=128, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "valid_dataset = AudioDataset(valid_data, path_to_data, tokenizer, \n",
    "                             n_fft=512, \n",
    "                             n_mels=128, \n",
    "                             center=True, \n",
    "                             max_tokenized_length=100, \n",
    "                             max_audio_len=25, \n",
    "                             sr=16000)\n",
    "model = Transformer(vocab_size=len(tokenizer),\n",
    "                    n_mels=128,\n",
    "                    enc_seq_len=25, \n",
    "                    dec_seq_len=100,\n",
    "                    hidden_dim=16, \n",
    "                    enc_num_layers=2, \n",
    "                    dec_num_layers=2, \n",
    "                    num_heads=3, \n",
    "                    ff_dim=128, \n",
    "                    device=device,\n",
    "                    dropout=0.0, \n",
    "                    sr=16000, \n",
    "                    n_fft=512,\n",
    "                    padding_idx=tokenizer.pad_token_id)\n",
    "\n",
    "\n",
    "        #.bias.data.fill_(0.01)\n",
    "model.apply(weights_init_xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef55a1-3645-448c-beee-565d8cc5ee39",
   "metadata": {},
   "source": [
    "n_fft=1024, win_lenght=1024, hop_lenght=256, n_mels=64, center=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d6466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94544c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import word_error_rate\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, \n",
    "                     dataset, \n",
    "                     loss_function,\n",
    "                     strat_array=None,\n",
    "                     device=torch.device(\"cuda\"),\n",
    "                     random_state: int=69, \n",
    "                     shuffle: bool=True, \n",
    "                     n_folds: int=10, \n",
    "                     epochs: int=10, \n",
    "                     lr: float=1e-6,\n",
    "                     start_fold: int=0, \n",
    "                     batch_size: int=4,\n",
    "                     iters_to_accumulate=None,\n",
    "                     n_accumulated_grads: int = 0):\n",
    "    random.seed(random_state),\n",
    "    np.random.seed(random_state)\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)\n",
    "    \n",
    "    loss_function.to(device)\n",
    "    if strat_array:\n",
    "        kfold = StratifiedKFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset, strat_array)\n",
    "    else: \n",
    "        kfold = KFold(n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        split = kfold.split(dataset)\n",
    "\n",
    "    for fold, (train_ids, eval_ids) in enumerate(split):\n",
    "        if fold >= start_fold:\n",
    "            print(f'FOLD {fold}')\n",
    "            print('--------------------------------')\n",
    "\n",
    "            optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr = 4e-2,\n",
    "        )\n",
    "\n",
    "            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                          train_subsampler, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "\n",
    "            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n",
    "            eval_loader = torch.utils.data.DataLoader(\n",
    "                          eval_subsampler,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=True)\n",
    "            \n",
    "            total_steps = len(train_loader) * epochs \n",
    "\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "            for epoch_i in range(epochs):\n",
    "                train_metrics, t_preds = train_epoch(model, train_loader, dataset.tokenizer, loss_function, optimizer, scheduler, device)\n",
    "                eval_metrics, preds = eval_epoch(model, eval_loader, dataset.tokenizer, loss_function, device)\n",
    "                print(f\"EPOCH: {epoch_i}\")\n",
    "                print(train_metrics)\n",
    "                print(eval_metrics)\n",
    "                print(t_preds)\n",
    "                print(preds)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a6081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d83303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я люблю дашу'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = tokenizer.encode(\"я люблю дашу\")\n",
    "tokenizer.decode(string, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92943ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67efaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fedor\\PycharmProjects\\asr-transformer\\venv\\lib\\site-packages\\torchaudio\\functional\\functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  1,  79, 114,  69, 199,  81, 208, 188, 105, 202,  66, 220, 179,  88,\n",
       "        186, 102, 205, 220, 124, 111, 214,  77,  65,  64,  77,  74, 101, 209,\n",
       "         81, 178, 220, 107, 104, 209, 205,  68, 201,  69, 105,  79, 212, 191,\n",
       "         70,  69, 102, 223,  65,  91,  75, 114,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['encoded_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bfb3b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 79, 114,  69, 199,  81, 208, 188, 105, 202,  66, 220, 179,  88, 186,\n",
       "        102, 205, 220, 124, 111, 214,  77,  65,  64,  77,  74, 101, 209,  81,\n",
       "        178, 220, 107, 104, 209, 205,  68, 201,  69, 105,  79, 212, 191,  70,\n",
       "         69, 102, 223,  65,  91,  75, 114,   2,   4,   4,   4,   4,   4,   4,\n",
       "          4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "          4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "          4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "          4,   4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['true_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7e833",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0747826ace1342c7a7c062314ebdd056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be6e054a2bd446fbdb98ebce2e4fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "{'Train Loss': 4.788388433910551, 'Train Word Accuracy': -0.13486027717590332, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 4.725820541381836, 'Val Word Accuracy': 0.0, 'Val Accuracy': 0.0}\n",
      "ссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссс\n",
      "сссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссс\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be79e1697f3a483bb14039a6ecde33c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f952f187ecd45d6aa916111e4dab509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "{'Train Loss': 4.694956132343838, 'Train Word Accuracy': 0.0, 'Train Accuracy': 0.0}\n",
      "{'Val Loss': 4.714163011974758, 'Val Word Accuracy': 0.0, 'Val Accuracy': 0.0}\n",
      "ссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссс\n",
      "сссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссссс\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5ee376e53d4816ac4634934bd1b7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_validation(model = model,\n",
    "                 dataset=train_dataset, \n",
    "                 loss_function=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction=\"mean\"), \n",
    "                 device=torch.device(\"cuda\"),\n",
    "                 random_state=69,\n",
    "                 shuffle=True,\n",
    "                 batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
